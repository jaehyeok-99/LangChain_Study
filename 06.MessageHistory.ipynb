{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"session_id\": \"chat\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"사용자의 질문에 2문장 이내로 짧게 대답해\"),\n",
    "    HumanMessage(content=\"오늘은 피자를 먹어야지!\"),\n",
    "    AIMessage(content=\"정말 좋은 생각이야. 음료는 무엇으로 할 거야?\"),\n",
    "    HumanMessage(content=\"내일은 수영을 가야지!\"),\n",
    "    AIMessage(content=\"수영이라니, 정말 좋은 운동이야. 수영장은 어디로 다녀?\"),\n",
    "    HumanMessage(content=\"주말에는 영화를 보러 갈 거야!\"),\n",
    "    AIMessage(content=\"주말이 벌써부터 기다려지겠는걸? 보려고 생각해둔 영화가 있어?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주말에 영화를 보러 간다고 했어! 계획이 잘 되길 바라.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    messages + [HumanMessage(content=\"주말에 내가 뭐하러 간다고 했지?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주말에 뭐하러 간다고 했는지 물어보셨어요. 답변은 주말에 영화를 보러 간다고 하셨죠.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"방금 내가 무슨 질문을 했지?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:load_history] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:load_history] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:check_sync_or_async] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:check_sync_or_async > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:check_sync_or_async > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: 사용자의 질문에 2문장 이내로 짧게 대답해\\nHuman: 오늘은 피자를 먹어야지!\\nAI: 정말 좋은 생각이야. 음료는 무엇으로 할 거야?\\nHuman: 내일은 수영을 가야지!\\nAI: 수영이라니, 정말 좋은 운동이야. 수영장은 어디로 다녀?\\nHuman: 주말에는 영화를 보러 갈 거야!\\nAI: 주말이 벌써부터 기다려지겠는걸? 보려고 생각해둔 영화가 있어?\\nHuman: 주말에 내가 뭐하러 간다고 했지?\\nAI: 주말에 영화를 보러 간다고 했어! 계획이 잘 되길 바라.\\nHuman: 방금 내가 무슨 질문을 했지?\\nAI: 주말에 뭐하러 간다고 했는지 물어보셨어요. 답변은 주말에 영화를 보러 간다고 하셨죠.\\nHuman: 내가 수영은 언제 간다고 했지?\\nAI: 내일 수영을 간다고 하셨어요. 계획 잘 실천하길 바랄게요!\\nHuman: 내가 수영은 언제 간다고 했지?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:check_sync_or_async > chain:RunnableSequence > llm:ChatOpenAI] [1.17s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"내일 수영을 간다고 하셨습니다. 재미있게 다녀오세요!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"내일 수영을 간다고 하셨습니다. 재미있게 다녀오세요!\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 20,\n",
      "                \"prompt_tokens\": 285,\n",
      "                \"total_tokens\": 305,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_b8bc95a0ac\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-bbc52c70-7ffc-4243-916b-15e155906815-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 285,\n",
      "              \"output_tokens\": 20,\n",
      "              \"total_tokens\": 305,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 20,\n",
      "      \"prompt_tokens\": 285,\n",
      "      \"total_tokens\": 305,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_b8bc95a0ac\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:check_sync_or_async > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:check_sync_or_async > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"내일 수영을 간다고 하셨습니다. 재미있게 다녀오세요!\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:check_sync_or_async > chain:RunnableSequence] [1.17s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"내일 수영을 간다고 하셨습니다. 재미있게 다녀오세요!\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:check_sync_or_async] [1.17s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"내일 수영을 간다고 하셨습니다. 재미있게 다녀오세요!\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory] [1.17s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"내일 수영을 간다고 하셨습니다. 재미있게 다녀오세요!\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'내일 수영을 간다고 하셨습니다. 재미있게 다녀오세요!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"내가 수영은 언제 간다고 했지?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'좋은 생각이에요! 수영은 건강에 매우 좋고 스트레스 해소에도 도움이 됩니다. 어떤 계획을 세우셨나요? 수영을 얼마나 자주 하시나요?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_01 = {\n",
    "    \"configurable\": {\n",
    "        \"session_id\": \"chat_01\"\n",
    "    }\n",
    "}\n",
    "\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"내일은 수영을 가야지!\")],\n",
    "    config=config_01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'내일 수영을 가기로 하셨다고 하셨죠! 수영을 통해 즐거운 시간 보내시길 바랍니다. 혹시 다른 계획이나 준비할 것이 필요하신가요?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"내일 뭐하러 간다고 했지?\")],\n",
    "    config=config_01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'어떤 상황에 대해 말씀하시는 건가요? 구체적인 정보나 맥락을 알려주시면 더 정확하게 답변해드릴 수 있을 것 같습니다.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_02 = {\n",
    "    \"configurable\": {\n",
    "        \"session_id\": \"chat_02\"\n",
    "    }\n",
    "}\n",
    "\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"언제 간다고 했지?\")],\n",
    "    config=config_02\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'정확한 시간은 언급하지 않으셨습니다. 내일 수영을 간다고 하셨는데, 특정 시간이나 장소에 대한 계획이 있으신가요? 일정이 어떻게 되는지 말씀해 주시면 도움이 될 것 같아요!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"언제 간다고 했지?\")],\n",
    "    config=config_01\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
